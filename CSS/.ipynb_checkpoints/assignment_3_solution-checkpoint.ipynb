{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.probability import FreqDist\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert the input text to a list of sentences. Then, compute the\n",
    "number of sentences in the given Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of sentences :  79\n"
     ]
    }
   ],
   "source": [
    "text = open(\"Article.txt\", \"r\").read()\n",
    "sentences = sent_tokenize(text)\n",
    "doc_count = len(sentences)\n",
    "\n",
    "print(\"No of sentences : \",doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the frequency of words in each sentence: the output should\n",
    "be a dictionary where each key is a sentence and the value is also a\n",
    "dictionary of word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "stemmer = PorterStemmer()\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    fdist = dict(FreqDist(words))\n",
    "    corpus[sentence] = fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate Term frequency for each word in a sentence\n",
    "4. Create a matrix termFrequency: The termFrequency matrix should\n",
    "be a dictionary where each key is a sentence and the value is also a\n",
    "dictionary of word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "termFrequency = {}\n",
    "\n",
    "for sent,fdist in corpus.items():\n",
    "    tf_table = {}\n",
    "    count_of_words_in_sentetnce = len(fdist)\n",
    "    \n",
    "    for word,freq in fdist.items():\n",
    "        tf_table[word] = freq / count_of_words_in_sentetnce\n",
    "    termFrequency[sent] = tf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. For each word compute how many sentences contain that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFrequency = {}\n",
    "\n",
    "for sent,fdist in corpus.items():\n",
    "    for word,freq in fdist.items():\n",
    "        if word in docFrequency:\n",
    "            docFrequency[word] += 1\n",
    "        else:\n",
    "            docFrequency[word]  = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculate IDF for each word in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "invDocFrequency = {}\n",
    "\n",
    "for sent,fdist in corpus.items():\n",
    "    idf_table = {}\n",
    "    \n",
    "    for word in fdist.keys():\n",
    "        idf_table[word] = math.log(doc_count / float(docFrequency[word]))\n",
    "    invDocFrequency[sent] = idf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compute the TF-IDF for each word in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "for (sent1,tf_table) , (sent2,idf_table) in zip(termFrequency.items(),invDocFrequency.items()):\n",
    "    tf_idf_for_sent = {}\n",
    "\n",
    "    for (tf_word,tf) , (idf_word,idf) in zip(tf_table.items(),idf_table.items()):\n",
    "        word = tf_word # or word = idf_word\n",
    "        sent = sent1 # or sent = sent2\n",
    "        tf_idf_for_sent[word] = float(tf * idf)\n",
    "    \n",
    "    tf_idf[sent1] = tf_idf_for_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the TF-IDF computed in (7) and give a weight for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "senetence_weights = {}\n",
    "\n",
    "for sent,tf_idf_for_sent in tf_idf.items():\n",
    "    sentence_weight = 0\n",
    "    words_count = len(tf_idf_for_sent)\n",
    "    \n",
    "    for word,tf_idf_score in tf_idf_for_sent.items():\n",
    "        sentence_weight += tf_idf_score\n",
    "    \n",
    "    senetence_weights[sent] = sentence_weight / words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Threshold: compute the average sentence weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weight = 0\n",
    "\n",
    "for sent,sent_weight in senetence_weights.items():\n",
    "    total_weight += sent_weight\n",
    "\n",
    "threshold = total_weight / doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Generate the summary : select a sentence for summarization if the\n",
    "weight of the sentence exceeds the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you haven't subscribed yet, you can do that by clicking here.\n",
      "Will it help if everyone wears a mask?\n",
      "Is keeping everyone two metres apart far enough?\n",
      "Some researchers aim to learn more about transmission by trying to make invisible sneezes, coughs and breaths more visible.\n",
      "Here's a closer look at that research and what it might reveal.\n",
      "How do scientists think COVID-19 is transmitted?\n",
      "Touches objects or surfaces on which droplets have landed and then touches their eyes, nose or mouth (contact transmission).\n",
      "Why is 2 metres the recommended distance for preventing transmission?\n",
      "Then, in 1934, W.F.\n",
      "Wells proposed that could explain how diseases are transmitted.\n",
      "Why don't experts think the virus is airborne?\n",
      "\"Does it mean that COVID-19 is spreading from person to person through aerosols?\n",
      "I would say definitively not,\" Loeb said.\n",
      "Is there evidence the virus could be spread farther than 2 metres?\n",
      "Within the chamber, droplets remained suspended for up to three minutes.\n",
      "What does that say about the 2-metre guideline?\n",
      "Mubareka stands by the two-metre guideline despite the findings of her cough chamber study.\n",
      "Second OpinionShould masks be mandatory in public to stop the spread of COVID-19?\n",
      "\"And that's really the key variable — that's what really determines your risk,\" she said.\n",
      "That may change, she added, with the recent invention of particle samplers designed specifically for viruses.\n",
      "\"They're basically saying what's theoretically possible,\" he said.\n",
      "But are coughing and sneezing all we need to worry about?\n",
      "\"It's just that maybe the dispersion is a little bit more limited.\"\n",
      "It found the louder someone spoke, the more droplets were emitted.\n",
      "So what about using masks to curb the spread of COVID-19?\n",
      "Some does leak out the sides, top and bottom, but without much momentum.\n",
      "Many governments haven't waited.\n",
      "To read the entire Second Opinion newsletter every Saturday morning, subscribe by clicking here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = \"\"\n",
    "\n",
    "for sent,sent_weight in senetence_weights.items():\n",
    "    if(sent_weight>threshold):\n",
    "        summary += sent + \"\\n\"\n",
    "print(summary)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
